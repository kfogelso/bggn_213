---
title: "breast_cancer_mini_project"
author: "Kelly_F"
date: "10/27/2021"
output:
  pdf_document: default
  html_document: default
---
# Exploratory Analysis 
```{r}
# Import Raw Data
wisc.df <- read.csv("./WisconsinCancer.csv",row.names=1)
head(wisc.df)

# Remove diagnosis column
wisc.data <- wisc.df[,-1]
head(wisc.data)

# Remove "X" column of NA values
dim(wisc.data)
wisc.data <- wisc.data[, 1:30] 

# Create diagnosis vector & factor data
diagnosis <- as.factor(wisc.df$diagnosis)
str(diagnosis)
```
> Q1. How many observations are in this dataset?

569 observations
```{r}
dim(wisc.df)
```

> Q2. How many of the observations have a malignant diagnosis?

212 are malignant 
```{r}
#Option 1
length(grep("M", diagnosis))

#Option 2
dim(subset(wisc.df, diagnosis=="M"))
```

> Q3. How many variables/features in the data are suffixed with _mean?

10
```{r}
colnames(wisc.df)
length(grep("_mean", colnames(wisc.df)))
```
# Performing PCA

```{r}
# Check column means and standard deviations
hist(colMeans(wisc.data))
hist(apply(wisc.data,2,sd))

# Perform PCA on wisc.data and transform data due to large variation 
wisc.pr <- prcomp(wisc.data, scale=TRUE) 

# Look at summary of results
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27% 

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

Three

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

Seven

# Interpreting PCA Results 

```{r}
# Generate biplot
biplot(wisc.pr)
```
> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

It is difficult to understand. There are many overlapping points with too many text labels present on the plot. With the current plot, its difficult to tell which features may be driving separation in the data 

```{r}

# R base plot: plot PC1 & PC1, color by diagnosis 
plot(wisc.pr$x[, 1:2], col=diagnosis)

# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1,3)], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")

```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

There is clearer separation of points in the graph of PC1 vs PC2, due to the fact that more variance is explained in the plot when compared to PC1 vs PC3

```{r}
# Create clearer graphs in ggplot 
library(ggplot2)

# Create dataframe of PC values 
head(wisc.pr$x)
df.pc <- data.frame(wisc.pr$x)
df.pc$diagnosis <- diagnosis 

ggplot(df.pc) +
  aes(x=PC1, y=PC2, col=diagnosis) + 
  geom_point()
```

# Variance Explained 

```{r}
# Calculate variance of each principal component
wisc.pr$sdev 
pr.var <- wisc.pr$sdev^2 #calculate variance 
head(pr.var)

# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
head(pve)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )

## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)

```

# Communicating PCA Results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

-0.2608538 
(This # is the influence [relative magnitude] of this feature on the PC in question)


```{r}
wisc.pr$rotation["concave.points_mean", "PC1"]
```
> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

5 principal componenets 
```{r}
summary(wisc.pr)
```

# Hierarchical clustering

```{r}
# Scale the wisc.data
data.scaled <- scale(wisc.data)

# Calculate Euclidean distance between all points 
data.dist <- dist(data.scaled)

# Create hclust model
wisc.hclust <- hclust(data.dist, method="complete")

```
## Results of HClust

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

19

```{r}
# Plot Cluster Dendrogram 
plot(wisc.hclust)
abline(h=19, col="red", lty=2) #lty=2 specifies a dashed line 
```
## Selecting number of clusters 
```{r}
# Cut hclust data into 4 clusters 
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
head(wisc.hclust.clusters)

# Compare cluster membership to diagnosis 
table(wisc.hclust.clusters, diagnosis)
```
> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

No, 4 is the optimal cluster number. 
If you decrease below 4 clusters, all M & B are in the same cluster (#1). 
Increasing beyond 5 clusters further fragments the M & B cases into non-useful clusters. 

```{r}
for (i in 2:10){
  table <- table(cutree(wisc.hclust, k=i), diagnosis)
  print(table)
}

```
## Using Different Methods

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning. 
Try the following methods:  "single", "complete", "average", "ward.D2".

My favorite results come from "ward.D2". 

By visually inspecting the graphs, we see that the Dendrogram can be clearly cut into two clusters. When the results of hclust w/ data grouped into two clusters are plotted against diagnosis, nearly every case segregates into one of the two clusters: 

164 malignant in cluster 1 & 337 benin in cluster 2. Only 68 samples unassigned. 
  
For the other methods, it is hard to "cut the tree" into any meaningful clusters that segregate the data into malignant vs benign clusters. 

```{r}
# Compare all 4 hclust clustering methods 

# Create list of method names for for loop
hclust_methods <- c("single", "complete", "average", "ward.D2")

for (i in 1:length(hclust_methods)){
  wisc.hclust <- hclust(data.dist, method=hclust_methods[i])
  plot(wisc.hclust, main=hclust_methods[i])

}

```

```{r}
# ward.D2 looks the best (all points break into two clusters), so lets inspect the clustering results vs diagnosis to see if diagnosis segregates 

table(cutree(hclust(data.dist, method="ward.D2"), k=2), diagnosis)

```
# Combining Methods

```{r}
# Determine number of principal components to describe at least 90% of variability
summary(wisc.pr)

# Complete hclust with method="ward.D2"
# Perform hclust on distance matrix of first 7 principal components of "wisc.pr" 

wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")

# Plot hclust dendrogram
plot(wisc.pr.hclust)

```
```{r}
# Cut dendrogram into two branches to see if the data is clustering by diagnosis 
grps <- cutree(wisc.pr.hclust, k=2)
table(grps, diagnosis)
```
```{r}
# Plot PC1 & 2 and color by hclust cluster membership
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
# Plot PC1 & 2 and color by diagnosis
plot(wisc.pr$x[,1:2], col=diagnosis)

# Factor and reorder groups so that colors of diagnosis and cluster membership plots line up
g <- as.factor(grps)
levels(g)

# Reorder factors 
g <- relevel(g,2)
levels(g)

# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```
```{r}
# Cut "wisc.pr.hclust" clustering model from above into 2 clusters and assign to new variable 

wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)

# Compare hclust results with diagnoses
table(wisc.pr.hclust.clusters, diagnosis)

```
> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

The new model built on the PCA results does a pretty good job of separating out the two diagnosis. 188 malignant cases are assigned to cluster 1 and 329 benign cases assigned to cluster 2. Overall, only 52 cases don't match the "right" cluster. This performs better than the hclust model built on the euclidean distances of the scaled wisc.data (question 13). 

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

Both hclust methods w/ models built on euclidean distances from the scaled wisc.data perform fairly well at separating the diagnosis. 

When using the complete method, at k=4 clusters, 165 malignant cases are assigned to cluster 1, and 343 benign cases are assigned to cluster 3. When using the ward.d2 method on the wisc.disc distance matrix, fewer clusters (k=2) are needed to segregate out malignant and benign samples, w/ 164 malignant cases assigned to cluster 1 and 337 benign cases assigned to cluster 2.

The hclust model built on PCA results performs the "best" overall. With two clusters, its able to separate 188 malignant cases into cluster 1 and 329 benign cases into cluster 2. 

```{r}
# Compare how well different clustering methods work for separating diagnosis
# Note- kmeans section was optional. 

# Hclust w/ euclidean distances, method = complete 
hclust_euclidean_complete <- table(wisc.hclust.clusters, diagnosis)
hclust_euclidean_complete 

# Hclust w/ euclidean distances, method = ward.D2
hclust_euclidean_ward <-table(cutree(hclust(data.dist, method="ward.D2"), k=2), diagnosis)
hclust_euclidean_ward

# clust w/ PCA, method = ward.D2
hclust_pca_ward <- table(wisc.pr.hclust.clusters, diagnosis)
hclust_pca_ward
```
# Sensitivity and Specificity 
> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

The hclust clustering model built on the first 7 PCs (PCA model) with ward.d2 method.  88.67% sensitivity & 93.2% specificity. 

Note: 

Sensitivity= ability to correctly detect ill patients who do have the condition.
TP/(TP+FN)

Specificity= ability to correctly reject healthy patients w/o a condition. 
TN/(TN+FN)

```{r}
# True number of malignant and benign cases
length(grep("M", diagnosis))
length(grep("B", diagnosis))

# hclust_euclidean_complete
# Sensitivity 
165/212
# Specificity 
343/(343+40)

# hclust_euclidean_ward
# Sensitivity 
164/212
# specificity 
337/(337+48)

# hclust_pca_ward
# sensitivity 
188/(212)
# specificity 
329/(329+24)

# Note... need to find a better way to calculate this w/o hard coding 
```
# Prediction 

Project new cancer cell data on previous PCA space
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url) # Read in new dataset 
npc <- predict(wisc.pr, newdata=new)
npc

# Generate plot
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
> Q18. Which of these new patients should we prioritize for follow up based on your results?

We should prioritie patient #2, who is in the red (malignant) cluster. 


# Session Info
```{r}
sessionInfo()

```

